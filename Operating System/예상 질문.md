## Index

### [질문 목록](#질문-목록)

### [Process & Thread](#Process와-Thread)

- 프로세스

- 멀티 프로세스

- 멀티 스레드

- 멀티 프로세스 vs 멀티 스레드

- 멀티 프로세스 환경에서 프로세스간 데이터를 주고 받는 방법

- 멀티 프로세스 환경에서 동기화 문제를 해결하는 방법

- 교착 상태(데드락)

### [메모리 관련](#메모리)

- 페이징

- 세그멘테이션

- 가상 메모리 

### [추가 사항들](#추가-사항)

- Blocking I/O vs Non Blocking I/O

- 커널

- 캐시

- 인터럽트



## 질문 목록

### 프로세스와 스레드

1. 프로세스와 스레드가 무엇인지 설명해주세요.

2. 이 둘은 각각 메모리 영역을 어떻게 할당받나요?

3. 프로세스가 생성되고 종료될 때까지의 상태 변화를 설명해보세요.

4. 왜 스레드는 Stack을 개별적으로 소유하나요?

5. CPU는 어떻게 Code 영역에서 명령어를 읽을 수 있나요?

6. 프로세스가 실행파일이 메모리에 적재되고 CPU를 할당받아 실행되는 것을 의미한다고 하였는데, 실행파일은 어떻게 만들어지나요?

### 멀티 프로세스와 멀티 스레드

1. 멀티 프로세스와 멀티 스레드를 공통점과 차이점을 기준으로 설명해주세요.

2. Context Switch에 대해서 들어보셨나요? 설명해주세요.

3. PCB는 왜 필요할까요?

4. 각각의 경우 프로세스의 상태는 어떻게 변화하나요?

5. 어떨 때 멀티 프로세스를 어떨 때 멀티 스레드를 사용하나요?

6. 멀티 프로세스 환경에서 어떻게 데이터를 주고 받나요?

7. 각각의 방법의 장단점에는 무엇이 있나요?

### 동기화 문제

1. 멀티 프로세스 환경에서 동기화 문제가 발생할 수 있는데 이 문제는 무엇이고 해결할 수 있는 방법은 무엇이 있는지 설명해주세요.

2. 각각의 방법이 어떻게 작동하는지 설명해주세요.

### 교착 상태

1. 교착상태란 무엇인가요?

2. 데드락은 언제 발생하나요?

3. 데드락은 어떻게 해결할 수 있나요?

### 페이징과 세그멘테이션

1. 페이징과 세그멘테이션을 공통점과 차이점을 기준으로 설명해주세요.

2. 그 둘의 문제점을 설명해주세요.

3. 그 문제점을 해결한 방법이 있다면 설명해주세요.

### 가상메모리

1. 가상 메모리가 무엇인가요?

2. CPU의 요청이 들어오면 사용될 주소 공간을 page 단위로 메모리에 적재하는 방법은 무엇인가요?

3. 해당 방법의 장점은 무엇인가요?

4. 만약 CPU가 무효 비트로 표시된 page에 접근하게 되면 어떤 상황이 벌어지는지 설명해주세요.

5. 만약 빈 프레임이 없다면 교체할 페이지는 어떻게 결정하나요?

6. 프로세스를 스케줄링하기 위한 Queue에는 어떤 종류가 있나요?

7. 프로세스들을 넣고 빼주는 스케줄러는 어떤 종류가 있나요?

### 그외

1. 캐싱 라인이 무엇인지 아시나요?

2. 캐시의 적중률을 극대화 시키기 위한 방법을 설명해주세요.

3. 인터럽트의 종류에는 무엇이 있나요?

4. 인터럽트의 처리 과정을 설명해주세요.

5. 시스템콜의 과정을 설명해주세요.

6. IPC란 무엇인가요?

7. 동기와 비동기를 차이점을 기준으로 설명해주세요.



## Process와 Thread

→ `메모리`와 `CPU 관점`에서 바라보는 것이 핵심이다.

### Process (프로세스)

- 프로세스란?

  → `실행파일(program)`이 `memory에 적재`되고 `CPU를 할당`받아 실행되는 것을 뜻한다.

  (program은 단순히 명령어 리스트를 포함하는 파일이다.)

- 프로세스가 메모리에 적재되면?

  → 각 프로세스는 `독립적`으로 `Code, Data, Stack, Heap`의 영역을 할당받는다.

  - 프로세스의 Memory 영역

    - Code 영역 : `프로그램의 코드`가 저장되는 메모리 영역
    
    - Data 영역 : 프로그램의 `전역 변수`와 `static 변수`가 저장되는 메모리 영역
    
    - Stack 영역 : `함수 호출`시 생성되는 `지역변수`와 `매개변수`가 저장되는 임시 메모리 영역
    
    - Heap 영역 : 프로그래머가 `동적`으로 `공간을 할당, 해제`하는 메모리 영역

  - Compile time vs Run time

    - Compile time

      → 개발자에 의해 `소스코드`가 작성되고 `컴파일 과정`을 통해 컴퓨터가 인식할 수 있는 `기계어 코드`로 변환되어 `실행 가능한 프로그램`이 되는 과정이다.

    - Run time

      → 컴파일을 마친 응용 프로그램이 사용자에 의해 `실행되는 때`를 의미한다.

  - Compile 과정

    1. 전처리 과정

       → `전처리기`를 통해 `주석을 제거`하고 `헤더 파일을 삽입`하고 `매크로를 치환`하여 `소스코드 파일`을 `전처리된 소스코드 파일`로 변환하는 과정이다.

    2. 컴파일 과정

       → `컴파일러`를 통해 `언어의 문법을 검사`하고 `Data영역에 메모리를 할당함`으로써 `전처리된 소스코드 파일`을 `어셈블리어 파일`로 변환하는 과정이다.

    3. 어셈블 과정

       → `어셈블러`를 통해 `어셈블리어 파일`을 `기계어`로 쓰여진 `오브젝트 파일`로 변환하는 과정이다.

    4. 링킹 과정

       → `링커`를 통해 `오브젝트 파일들`과 `라이브러리 파일들`을 묶어 `하나의 실행파일`로 변환하는 과정이다.

- CPU가 어떤 코드를 읽을지 결정하려면?

  → CPU 내부에 있는 `PC (Program Counter) Register`가 `다음에 실행될 코드의 주소값`을 저장하고 있다. 메모리에 적재되어 있는 프로세스의 코드 영역의 명령어중에서 다음번 연산에 읽어야 할 명령어의 주소값을 PC Register가 순차적으로 가리키고, 해당 명령어를 읽어와서 CPU가 연산을 하게 된다.

- 프로세스를 스케줄링하기 위한 Queue에는 어떤 것이 있나?

  1. job queue

     → 시스템 내부에 있는 `모든 프로세스`의 집합이다.

  2. ready queue

     → 메인 메모리에 상주하면서 `실행될 준비`를 하고 있는 프로세스의 집합이다. (스케줄러에게 선택되어 CPU에 올라가기를 기다리는 프로세스들의 집합)

  3. wait queue

     → `입출력 장치를 기다리는` 프로세스의 집합이다. (입출력 장치와 CPU의 속도차이 때문에 wait queue가 존재한다.)

- 프로세스를 넣고 빼주는 스케줄러에는 어떤 것이 있나?

  1. 장기 스케줄러 (job scheduler)

     → `메모리`와 `디스크` 사이의 스케줄링을 담당한다.

     → `job queue`에서 `ready queue`로 옮겨질 프로세스를 선택하여 적재한다.

     (프로세스의 상태는 `new` → `ready` 혹은 `ready` → `terminate`로 변한다.)

     → 메모리에 `몇개의 프로그램을 적재할 것인지` 결정한다.

     → `실행 빈도가 낮다`.

  2. 단기 스케줄러 (CPU scheduler)

     → `CPU`와 `메모리` 사이의 스케줄링을 담당한다.

     → 메모리에 있는 프로세스 중 하나를 선택해서 `CPU에 적재`한다.

     (프로세스의 상태는 `ready` → `running` → `waiting` → `ready`로 변한다.)

     → `실행 빈도가 높다`.

  3. 중기 스케줄러

     → CPU를 차지하기 위한 경쟁이 심해질 때 `우선순위가 낮은 프로세스`들을 `swap out` 시킨다.

     (시분할 시스템에서 `메모리에 대한 가중을 완화`하기 위해 추가로 사용하는 스케줄러)

     (프로세스의 상태는 `ready` → `suspended`로 변한다.)

### Multi Process (멀티 프로세스)

- 멀티 프로세스란?

  → `2개 이상의 프로세스`가 동시에 실행되는 것 혹은 그렇게 보이는 것을 말한다.

  - 동시성과 병렬성

    동시에라는 말은 동시성과 병렬성 두가지를 의미한다.

    동시성 : `CPU core가 1개`일 때, 여러 프로세스를 짧은 시간동안 번갈아가며 연산하는 `시분할 시스템`으로 `동시에 실행되는 것처럼 보이는 것`을 의미한다.

    병렬성 : `CPU core가 여러개`일 때, 각각의 core가 각각의 프로세스를 연산함으로써 프로세스가 `실제로 동시에 실행되는 것`을 의미한다.

  → 이때 프로세스들은 `CPU와 메모리를 공유`하게 된다. 메모리의 경우에는 여러 프로세스들이 각자의 메모리 영역을 차지하며 동시에 적재된다. 반면 CPU는 매 순간 하나의 프로세스만 연산할 수 있다. 하지만 여러 프로세스들이 아주 짧은 시간 간격으로 CPU에서 번갈아서 실행되기 때문에 사용자의 입장에서는 여러 프로그램이 동시에 실행되는 것처럼 느껴진다. 이렇게 CPU의 작업 시간을 여러 프로세스들이 조금씩 나누어 쓰는 시스템을 `시분할 시스템`이라고 부른다.

- Context란?

  → `프로세스에 대한 총제적인 정보`를 의미하며 `PCB(Process Control Block)에 저장`된다.

  → Context Switch시 실행할 프로세스가 이전에 어디까지 명령을 수행했고 register에는 어떤 값이 저장되어 있는지에 대한 정보가 필요하여 Context를 저장할 필요가 있다.

- PCB(Process Context Block)란?

  → 운영체제가 `프로세스의 정보`들을 담은 `자료구조`이다.

  → 중요한 정보가 저장되어 있기 때문에 일반 사용자가 접근하지 못하도록 `커널 스택`에 위치하게 된다.

  → PCB에는 `프로세스의 상태, 번호`, `PC`, `Registers` (레지스터 값들), `Page table`, `Segment table` 등이 저장된다.

- Context Switch란?

  → 한 프로세스에서 다른 프로세스로 `CPU의 제어권이 넘어가는 것`을 의미한다.

  → 이때 이전 프로세스의 상태를 PCB에 저장하여 보관하고 새로운 프로세스의 PCB를 읽어서 보관된 상태를 복구하는 작업이 이루어진다.

- Process의 상태?

  - new(생성) : 프로세스가 `생성`된 상태
  
  - ready(준비) : `CPU만 할당`받으면 즉시 명령을 수행할 수 있도록 준비된 상태
  
  - running(실행) : 프로세스가 `CPU를 점유`하고 `명령을 수행중`인 상태
  
  - waiting(blocked, 대기) : CPU를 할당받아도 명령을 수행할 수 `없는` 상태 (I/O 요청 등)
  
  - terminated(종료) : 프로세스가 `종료`된 상태

### Multi Thread (멀티 스레드)

- 스레드란?

  → `하나의 프로세스` 내에서 실행되는 `동작의 단위`이다.

  → 하나의 프로세스에 속한 스레드들은 Code, Data, Heap 영역을 공유하고 Stack 영역은 개별적으로 가진다.

- 멀티 스레드란?

  → 하나의 프로세스가 `여러개의 동작 단위`를 가짐으로써 `동시에 여러개의 일을 수행`할 수 있도록 해준다.

  → 하나의 프로세스에 속한 스레드들은 `독립적인 Stack 메모리와 PC Register`를 필요로 한다.

- 스레드는 왜 독립적인 Stack 메모리 영역이 필요할까?

  → 스레드가 `독립적인 기능`을 실행한다는 것은 `독립적으로 함수를 호출함`을 의미한다. 스레드가 함수를 호출하기 위해서는 인자를 전달하고 Return Address를 저장하고 함수 내의 지역변수들을 저장해야 하므로 독립적인 Stack 메모리 공간이 필요하다.

- 프로세스 vs 스레드

  - 프로세스

    → 운영체제로부터 `자원을 할당받는 단위`로, 실행파일이 `메모리`에 적재되어 `CPU`를 할당받은 것이다.

    → 메모리 공간에 Code, Data, Stack, Heap 영역을 할당 받는다.

  - 스레드

    → 프로세스가 `할당받은 자원을 이용하는 실행의 단위`로 한 프로세스 내에서 실행되는 `동작의 단위`이다.

    → 프로세스 내에서 Stack 영역을 제외한 Code, Data, Heap 영역을 공유한다.

### Multi Process (멀티 프로세스) vs Multi Thread (멀티 스레드)

- 멀티 프로세스 vs 멀티 스레드 공통점

  - `동시에 여러 작업`을 수행한다.

- 멀티 프로세스 vs 멀티 스레드 차이점

  - 멀티 스레드는 멀티 프로세스보다 `적은 메모리 공간`과 `CPU 시간`을 차지한다.

  - 멀티 스레드는 멀티 프로세스보다 `Context Switching`이 빠르다.

  - 멀티 스레드는 `동기화 문제`와 `하나의 스레드의 장애`로 `전체 스레드가 종료`될 위험이 있다.

    멀티 프로세스는 하나의 프로세스가 죽더라도 다른 프로세스에 영향을 주지 않아 `안정성`이 높다.

  - `프로세스간 통신`보다 `스레드간 통신` 비용이 적어서 멀티 스레드의 경우 통신으로 인한 `오버헤드`가 적다.

- 멀티 프로세스를 사용하면 좋은 경우

  → `메모리 구분`이 필요하거나 `높은 안정성`이 필요할 때 사용하면 좋다.

- 멀티 스레드를 사용하면 좋은 경우

  → `자원을 효율적`으로 사용해야 하거나 `Context Switching`이 자주 일어나는 경우에 사용하면 좋다.

### Multi Process (멀티 프로세스) 환경에서 프로세스 간에 데이터를 주고 받는 방법

- 멀티 프로세스 환경에서 프로세스 간에 데이터를 주고 받는 방법

  → 원칙적으로 프로세스는 `독립적인 주소 공간`을 갖기 때문에 다른 프로세스의 주소공간을 참조할 수 없다.

  → 경우에 따라 운영체제는 프로세스 간의 자원 접근을 위한 메커니즘인 프로세스간 통신(IPC)를 제공한다.

- 프로세스간 통신(IPC, Inter Process Communication)이란?

  - 프로세스간 통신은 `여러 프로세스들`이 `동일한 자원을 공유`하는 과정으로 `공유 메모리`와 `메세지 전달`의 두가지 모델이 있다.

- 공유 메모리 모델

  → 프로세스들이 `메모리 공간의 일부를 공유`하여 `공유한 메모리 영역`에 `읽기/쓰기`를 수행하여 통신을 진행한다. (`공유 메모리 할당`은 `커널`에게 요청하여 진행된다.)

  → 공유 메모리 영역이 구축되고 나면 모든 접근이 `일반적인 메모리 접근`과 동일하므로 커널의 도움없이 `빠르게 데이터를 통신`할 수 있다는 장점이 있다.

  → 공유 메모리 방식에서 동시에 같은 메모리 위치에 접근하게 되면 `일관성 문제`가 발생할 수 있고 이에 대해서는 커널이 관여하지 않기 때문에 프로세스들끼리 직접 공유 메모리 접근에 대한 `동기화 문제를 책임`져야 한다.

- 메시지 전달 모델

  → `커널`에 `send`와 `receive`라는 연산을 보내어 데이터를 주고 받는 방식으로 `system call`을 사용하여 구현된다.

  → `충돌`을 회피할 필요가 없다는 장점이 있다. (`커널이 동기화를 제공`해준다.)

  → 메모리 공유보다 `속도가 느리다`는 단점이 있다.

  → 대표적인 예시로는 `pipe`, `socket`, `message queue` 등이 있다.

### Multi Process / Thread (멀티 프로세스 / 스레드) 환경에서 동기화 문제를 해결하는 방법

- 동기화 문제란?

  → 여러 스레드가 `동일한 자원`에 동시에 접근하여 엉뚱한 값을 `읽거나 수정하는` 문제이다.

- 동기화 문제를 해결하기 위한 방법은?

  → 동기화 문제를 해결하기 위해 `Mutex`, `Semaphore` 기법 등을 사용할 수 있다.

- Mutex란?

  → `하나의 스레드`만이 `공유 자원에 접근`할 수 있도록 하여 `경쟁 상황`을 방지하는 기법이다.

  → 하나의 스레드가 공유 자원에 `lock`을 걸면 다른 스레드는 `unlock`이 될 때까지 해당 자원에 접근할 수 없다. (`lock의 획득과 반환`을 통해 공유자원 접근을 제어한다.)

  → `acquire 함수`와 `release 함수`를 사용한다.

  → `busy waiting`을 통해 `CPU가 낭비`된다는 단점이 있다.

- Semaphore란?

  → `S개의 스레드`만이 `공유 자원에 접근`할 수 있도록 제어하는 `동기화 기법`이다.

  → 가용 자원의 수를 `S값`으로 초기화하고, 자원에 접근할 때에는 `S-- 연산`을 수행하여 세마포어 값을 감소시키고 자원의 사용이 끝나면 `S++ 연산`을 수행하여 세마포어 값을 증가시킨다. `세마포어 값이 0`이 되면 모든 자원이 사용중인 것을 의미하고 이후 자원을 사용하려는 프로세스는 세마포어 값이 `0보다 커질 때`까지 block 된다.

  → `wait 함수`와 `signal 함수`를 사용한다.

  → `Binary Semaphore`는 Mutex와 비슷하다.

  → `busy waiting`을 통해 `CPU가 낭비`된다는 단점이 있다.

- 임계영역이란?

  → `둘 이상의 프로세스나 스레드`가 `동시에 동일한 자원에 접근`하려고 하는 `프로그램의 코드 부분`을 의미한다.

  → 하나의 프로세스가 자신의 `임계구역을 수행`하는 동안에는 다른 프로세스는 그들의 임계구역에 들어갈 수 없어야 한다. 즉 임계구역 내의 코드는 `원자적으로 실행`되어야 한다.

  (임계구역에 진입하는 부분을 `entry section`이라고 부르고 임계구역에서 나오는 부분은 `exit section`이라고 부른다.)

  - 원자적

    어떤 연산이 `외부의 간섭`과 관계없이 `전체가 완료`되든지 `전혀 실행되지 않는 것`을 의미한다.

### 교착 상태 (Deadlock)

- 교착상태란?

  → `둘 이상의 스레드`가 `자원을 보유`한 채로 상대 스레드가 보유하고 있는 자원을 서로 `기다리면서` `무한 대기`에 빠지는 상황을 말한다.

- 데드락이 발생하는 조건은?

  1. 점유 대기 - 스레드가 자원을 보유한 상태로 다른 스레드가 보유한 자원을 `기다리는` 상황이어야 한다.
  
  2. 순환 대기 - 대기중인 스레드들이 `순환의 형태`로 자원을 대기하고 있어야 한다.
  
  3. 상호 배제 - 동시에 `한 스레드만`이 자원을 점유할 수 있다.
  
  4. 비선점 - 다른 스레드가 선점하고 있는 자원을 `강제로 선점할` 수 없다.

- 데드락 문제를 해결하려면?

  1. 무시

     → 아무런 조치도 취하지 않고 데드락을 무시한다.

     → 현대 시스템에서는 데드락이 `잘 발생하지 않고` `해결 비용`이 크기 때문에 무시가 많이 사용된다.

     → `시스템 성능 저하`가 없다.

  2. 예방

     → 데드락이 발생하는 `4가지 조건` 중 하나가 `성립되지 않도록` 한다.

     → `순환 대기`를 방지하는 것이 현실적으로 가능한 예방 기법이다.

     → `자원 사용의 효율성`이 떨어지고 비용이 크다.

  3. 회피

     → 스레드가 앞으로 자원을 어떻게 요청할 지에 대한 정보를 통해 `순환대기가 발생하지 않도록` 자원을 할당한다.

  4. 탐지 - 회복

     → `시스템 검사`를 통해 데드락 발생을 탐지하고 이를 회복시킨다.

     → `자원 사용의 효율성`이 떨어지고 비용이 크다.

------

## 메모리

### Paging (페이징)

- 페이징이란?

  → `프로세스`가 할당받은 `메모리 공간`을 일정한 `page 단위`로 나누어 `물리 메모리상`에 `연속되지 않은` 서로 다른 위치에 저장하는 `메모리 관리 기법`이다.

  - 논리적 주소 vs 물리적 주소 vs 주소 바인딩
    
    - 논리적 주소 : `프로세스`가 `메모리에 적재`될 때의 주소 공간으로 각 프로세스마다 `독립적`으로 할당되며 `0부터` 시작한다.
    
    - 물리적 주소 : 프로세스가 `실제로 메모리에 적재되는 위치`를 말한다.
    
    - 주소 바인딩 : `CPU`가 `기계어 명령`을 수행하기 위해 `논리적 주소`가 `실제 물리 메모리`의 어느 위치에 `매핑되는지 확인`하는 과정이다.

  → 페이징이 가능하도록 `물리 메모리`를 `page와 같은 크기의 frame`으로 미리 나누어 두어야 하고 모든 프로세스는 각각의 주소 변환을 위해 `Page Table`를 갖는다.

- 페이징 기법의 문제점은?

  → `메모리 단편화` 중에서 `내부 단편화`가 발생할 수 있다.

  - 메모리 단편화

    외부 단편화 : 메모리 공간들에 `크기가 작은 빈 공간들`이 사용되지 못하고 `낭비`되는 현상을 의미한다.

    내부 단편화 : `큰 메모리 공간`에 `작은 양의 데이터`가 할당되어서 공간이 모두 사용되지 않고 남아서 `낭비`되는 현상을 의미한다.

### Segmentation (세그멘테이션)

- 세그멘테이션이란?

  → `프로세스`가 할당받은 `메모리 공간`을 `논리적 의미 단위인 segment`로 나누어 `연속되지 않은 물리 메모리 공간`에 할당될 수 있도록 하는 `메모리 관리 기법`이다.

  → `Code, Data, Stack, Heap` 등 `기능 단위`로 Segment를 정의하는 경우가 많아 `접근 권한을 관리`하기가 편리하다.

  → Segmentation 기법에서는 `주소 바인딩`을 위해 모든 프로세스가 주소 변환을 위한 `Segment table`을 갖는다.

- 세그멘테이션 기법의 문제점은?

  → `서로 다른 크기의 세그먼트`들이 `적재되고 제거`되는 일이 반복되면 `외부 단편화`가 발생할 수 있다.

- Paged Segmentation이란?

  → `Segmentation을 기본`으로 하되 이를 다시 `동일한 크기의 Page`로 나누어 `물리 메모리`에 할당하는 메모리 관리 기법이다.

  → Segmentation 기법에서 발생하는 `외부 단편화` 문제를 해결하고 Process간의 `접근 권한 보호`가 이루어지도록하여 Paging 기법의 단점 또한 해결할 수 있다.

### 가상 메모리

- 가상 메모리란?

  → `프로세스 전체`가 `메모리에 올라가지 않더라도` 실행이 가능하도록 하는 기법이다.

  (프로그램의 `논리적 주소 영역`에서 필요한 부분만 물리적 메모리에 적재하고 필요하지 않은 메모리 공간은 `디스크`에 저장하게 된다.)

  → 사용자의 프로그램이 `물리적 메모리보다 크더라도` 실행이 가능하다는 장점이 있다.

- 요구 페이징이란?

  → `CPU의 요청`이 들어오면 `사용될 주소 공간`을 `page 단위`로 `메모리에 적재`하는 방법을 의미한다.

  → 당장 실행할 page만을 메모리에 적재하기 때문에 `메모리 사용량이 감소`하고 프로세스 전체를 메모리에 적재하는 `입출력 오버헤드`도 감소한다.

  → 요구 페이징 기법에서는 `Page Table`에 `유효/무효 비트`를 두어 각 페이지가 메모리에 존재하는지 표시한다.

- Page Fault가 발생하면?

  → `CPU`가 `무효 비트로 표시된 page에 접근`하는 상황을 Page Fault라고 한다.

  1. CPU가 페이지 N을 `참조`한다.

  2. Page Table에서 페이지 N이 `무효 상태`임을 확인한다.

  3. `MMU`에서 `Page Fault Trap`이 발생된다.

     (MMU는 무효 page에 접근했을 때 주소 변환을 담당하는 하드웨어이다.)

  4. 디스크에서 페이지 N을 빈 프레임에 `적재`하고 Page Table을 `업데이트` 한다.

- 교체할 Page는 어떻게 결정할까?

  → `Page Fault`가 발생하였는데 `물리적 메모리에 공간이 부족`한 경우 `디스크로 옮길` page를 결정해야 한다.  이 때 `어떤 page를 교체할 것이냐`를 결정하는 알고리즘이 Page 교체 알고리즘이다.

  - FIFO(First Come First Out) : 메모리에 올라온지 가장 오래된 page를 결정한다.
  
  - 최적 페이지 교체 : 앞으로 가장 오랫동안 사용되지 않을 page를 찾아서 교체한다. 실제 구현은 어렵다.
  
  - LRU(Least Recently Used) : 가장 오랫동안 사용되지 않은 page를 교체한다.
  
  - LFU(Least Frequently Used) : 참조 횟수가 가장 적은 page를 교체한다. 비용대비 성능이 좋지 않아서 잘 쓰이지 않는다.
  
  - MFU(Most Frequently Used) : 참조 횟수가 가장 많은 page를 교체한다.

------

## 추가 사항

### Blocking I/O vs Non Blocking I/O

- Blocking I/O란?

  → `I/O 작업`이 진행되는 동안 `유저 프로세스`가 `자신의 작업을 중단`한 채 I/O 작업이 끝날 때까지 `대기`하는 방식을 의미한다.

- Non Blocking I/O란?

  → `I/O 작업`을 호출했을 때 `유저 프로세스`가 작업을 중단하지 않고 `이어서 다른 일을 수행`하는 방식을 의미한다.

  → I/O 호출은 `즉시 리턴`하고 다른 작업을 수행하면서 중간중간 커널에 시스템콜을 보내서 I/O 작업이 완료되었는지 묻는다.

- sync vs async

  → sync : I/O 작업이 완료되면 작업의 결과를 `호출하는 함수`가 가지고 온다.

  → async : I/O 작업이 완료되면 `콜백 함수 호출을 통해 결과`를 받는다.

### 커널

- 커널이란?

  → `운영체제의 핵심`부분으로 `CPU, 메모리, 파일, 네트워크, 입출력 장치` 등의 `컴퓨터의 자원들을 관리`한다.

  → 사용자는 커널에 직접 접근할 수 없기 때문에 커널의 기능을 사용하려면 `시스템 콜`을 이용해야 한다.

- 시스템 콜이란?

  → `응용 프로그램의 요청`에 따라 `커널에 접근`하기 위한 `인터페이스`이다.

- 시스템 콜은 어떻게 부를까?

  → 사용자는 `쉘`을 통해 인터페이스를 제공받는다.

  → 쉘은 `사용자와 커널 사이의 인터페이스`로 `CLI(터미널 환경)`와 `GUI(그래픽 환경)`로 나뉜다.

- 시스템 콜의 순서는?

  1. `유저 프로세스`가 `시스템 콜`을 호출하면 `제어권`이 `커널`로 넘어온다. (`유저모드` → `커널모드`)

  2. 커널은 요청받은 시스템 콜에 대응하는 `서비스 루틴`을 호출한다.

     (커널은 내부적으로 기능별로 고유 번호를 할당하고 번호에 해당하는 `제어 루틴`을 내부에 정의해둔다.)

  3. 서비스 루틴의 처리가 끝나면 커널모드에서 유저모드로 전환이 된다.

### 캐시

- 캐시란?

  → `빈번하게 사용하는 데이터`를 저장하는 `임시 장소`이다.

  → 데이터에 접근하는 `시간을 절약`할 수 있어 속도가 느린 장치와 빠른 장치 사이의 `병목 현상`을 줄일 수 있다.

- 캐시의 적중률을 극대화 시키려면?

  → 캐시의 `지역성 원리`를 사용한다.

  → 지역성이란 기억 장치 내 정보를 균일하게 접근하는 것이 아니라 `어느 한 순간`에 `특정 부분을 집중적`으로 `참조하는 특성`을 가리킨다.

  → 시간 지역성 : 최근에 참조된 주소의 내용이 `곧 다시 참조`되는 특성이다.

  → 공간 지역성 : 참조된 데이터와 `가까운 위치`에 있는 데이터가 다시 참조되는 특성이다.

- 캐싱라인이란?

  → 캐시에 데이터를 저장하기 위한 `자료구조`이다. (데이터의 주소 등을 기록해둔 `태그들의 모임`이기도 하다.)

  1. Direct Mapped

     → `메인메모리`와 `캐시` 사이에 `매핑`이 되어 있다.

     → 장점 : 매핑되어 있으므로 `접근 속도`가 빠르다.

     → 단점 : 하나의 캐시 공간에 여러 곳의 메모리 공간이 매핑되므로 `충돌이 잦다`.

  2. Fully Associative

     → `비어있는` 캐시 메모리를 `탐색`하여 데이터를 집어넣는 방식이다.

     → 장점 : `충돌`의 위험이 적다.

     → 단점 : `매번 순차 탐색`을 해야하므로 `효율`이 낮다.

  3. Set Associative

     → `여러개`의 `Direct Mapped`을 가지는 방식이다.

     → Direct Mapped와 비교하여 `탐색의 시간`은 조금 길어지지만 `충돌의 위험`은 줄어든다.

### 인터럽트

- 인터럽트란?

  → `프로세스`를 실행하는 도중 `어떠한 상황`이 발생하여 실행중인 `프로세스를 중단`하고 `발생한 상황을 처리`한 뒤에 다시 `이전의 프로세스로 복귀`하는 것을 의미한다.

- 인터럽트의 종류는?

  1. 전원 이상 인터럽트

     → `정전`이나 `파워 이상` 등으로 인한 인터럽트이다.

  2. 기계 착오 인터럽트

     → `CPU 등의 기능적인 오류`로 인한 인터럽트이다.

  3. 입출력 인터럽트

     → `입출력 장치`가 데이터 전송 등의 동작 수행을 요구하는 인터럽트이다.

- 인터럽트의 처리과정은?

  1. `인터럽트 요청`이 들어온다.
  
  2. 실행중인 `프로세스가 중단`된다.
  
  3. `PCB`에 실행중이었던 프로세스의 상태가 저장된다. (`PC`도 저장한다.)
  
  4. 인터럽트를 요청한 `장치를 식별`하는 `처리 루틴`이 실행된다.
  
  5. 인터럽트의 `원인을 파악`하고 `실질적인 작업`을 수행하는 `서비스 루틴`이 실행된다. 만약 서비스 루틴을 실행하던 중 우선순위가 높은 인터럽트가 발생하면 다시 1~5 과정이 실행된다.
  
  6. `PCB`에 저장된 프로세스의 상태를 복구한다. (`PC`도 복구한다.)
  
  7. PC의 값을 이용하여 이전에 수행중이던 `프로그램을 재개`한다.
